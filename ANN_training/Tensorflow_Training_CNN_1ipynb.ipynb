{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2oab6H3BWALX",
    "outputId": "e260ca51-76b1-40ac-c9de-525006309430"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4lRRx5UUWBXG",
    "outputId": "20f65613-c0f7-484f-8047-8a5dcb0c6957"
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Set memory growth to avoid allocating all GPU memory at once\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         # Currently, memory growth needs to be the same across GPUs\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "#         # Set per_process_gpu_memory_fraction\n",
    "#         tf.config.experimental.set_virtual_device_configuration(\n",
    "#             gpus[0],\n",
    "#             [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*4)]  # Memory limit in MB\n",
    "#         )\n",
    "#     except RuntimeError as e:\n",
    "#         # Memory growth must be set before GPUs have been initialized\n",
    "#         print(e)\n",
    "# else:\n",
    "#     print(\"No GPU devices found\")\n",
    "\n",
    "# # Verify configuration\n",
    "# print(\"Physical devices:\", tf.config.experimental.list_physical_devices())\n",
    "# print(\"Logical devices:\", tf.config.experimental.list_logical_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qT-nJDExM2qI",
    "outputId": "bc876994-7c93-4af1-f1d9-545fa87891ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Columns: Index(['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax'], dtype='object')\n",
      "First few rows of the data:\n",
      "                                             filename  width  height   class  \\\n",
      "0  rgb_20240622112419726764_jpg.rf.21f698cc5c1740...    255     255     bus   \n",
      "1  rgb_20240622112419726764_jpg.rf.21f698cc5c1740...    255     255     car   \n",
      "2  rgb_20240622113116438046_jpg.rf.21f988c49c5be0...    255     255    stop   \n",
      "3  rgb_20240622112540883784_jpg.rf.221406a6ff8080...    255     255  person   \n",
      "4  rgb_20240622112540883784_jpg.rf.221406a6ff8080...    255     255     car   \n",
      "\n",
      "   xmin  ymin  xmax  ymax  \n",
      "0   124   108   191   152  \n",
      "1   212   127   253   153  \n",
      "2    51   170   190   223  \n",
      "3   125   121   132   152  \n",
      "4    54   125    65   133  \n",
      "Unique classes in the dataset: ['bus' 'car' 'stop' 'person' 'truck' 'edge lane' 'lanes' 'traffic light'\n",
      " 'pole' 'Green light' 'middle lane' 'StraightArrow' 'bicycle' 'red light'\n",
      " 'motorbike' 'road' 'Straight and Right Arrow' 'Right Arrow' 'walk way'\n",
      " 'Yellow light' 'straight and left arrow' 'motor' '90' 'left arrow' 'bird']\n",
      "Unique classes in labels after mapping: [12  0  4  1  9  7 16  2  6 15  8 21 10  3  5 17 13 24 11 20 14 29 18 23\n",
      " 25]\n",
      "CSV Columns: Index(['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax'], dtype='object')\n",
      "First few rows of the data:\n",
      "                                             filename  width  height  \\\n",
      "0  rgb_20240622111125769874_png.rf.036532cad78422...    255     255   \n",
      "1  rgb_20240622111125769874_png.rf.036532cad78422...    255     255   \n",
      "2  rgb_20240622112336394087_jpg.rf.000ef1efb34c96...    255     255   \n",
      "3  rgb_20240622112315076434_jpg.rf.03ed0a63181df0...    255     255   \n",
      "4  rgb_20240622112315076434_jpg.rf.03ed0a63181df0...    255     255   \n",
      "\n",
      "         class  xmin  ymin  xmax  ymax  \n",
      "0  Green light   100    86   106    96  \n",
      "1  Green light   126    88   130    95  \n",
      "2          car   113   126   142   147  \n",
      "3          car   210   123   255   162  \n",
      "4          car    40   125    70   146  \n",
      "Unique classes in the dataset: ['Green light' 'car' 'person' 'red light' 'truck' 'edge lane' 'bicycle'\n",
      " 'stop' 'traffic light' 'lanes' 'pole' 'motorbike' 'middle lane'\n",
      " 'Right Arrow' 'Straight and Right Arrow' 'walk way' 'StraightArrow' 'bus'\n",
      " 'pottedplant' 'Yellow light' 'bird' 'straight and left arrow']\n",
      "Unique classes in labels after mapping: [15  0  1  3  9  7 10  4  2 16  6  5  8 24 13 11 21 12 22 20 25 14]\n",
      "Epoch 1/30\n",
      "1934/1934 [==============================] - 2473s 1s/step - loss: 0.0991 - accuracy: 0.4388 - val_loss: 0.0905 - val_accuracy: 0.4768 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "1934/1934 [==============================] - 2508s 1s/step - loss: 0.0913 - accuracy: 0.4579 - val_loss: 0.0810 - val_accuracy: 0.4798 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "1934/1934 [==============================] - 2502s 1s/step - loss: 0.0889 - accuracy: 0.4643 - val_loss: 0.0782 - val_accuracy: 0.4880 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "1934/1934 [==============================] - 2628s 1s/step - loss: 0.0850 - accuracy: 0.4785 - val_loss: 0.0781 - val_accuracy: 0.5105 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "1934/1934 [==============================] - 2914s 2s/step - loss: 0.0843 - accuracy: 0.4805 - val_loss: 0.0790 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "1934/1934 [==============================] - 2840s 1s/step - loss: 0.0839 - accuracy: 0.4878 - val_loss: 0.0753 - val_accuracy: 0.5075 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "1934/1934 [==============================] - 6342s 3s/step - loss: 0.0815 - accuracy: 0.4919 - val_loss: 0.0749 - val_accuracy: 0.5149 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "1934/1934 [==============================] - 2575s 1s/step - loss: 0.0808 - accuracy: 0.4945 - val_loss: 0.0731 - val_accuracy: 0.5142 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "1934/1934 [==============================] - 2579s 1s/step - loss: 0.0798 - accuracy: 0.4960 - val_loss: 0.0727 - val_accuracy: 0.5329 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "1934/1934 [==============================] - 2639s 1s/step - loss: 0.0790 - accuracy: 0.5012 - val_loss: 0.0728 - val_accuracy: 0.5344 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "1934/1934 [==============================] - 2881s 1s/step - loss: 0.0792 - accuracy: 0.4964 - val_loss: 0.0731 - val_accuracy: 0.5516 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "1934/1934 [==============================] - 2945s 2s/step - loss: 0.0782 - accuracy: 0.5034 - val_loss: 0.0718 - val_accuracy: 0.5404 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "1934/1934 [==============================] - 2465s 1s/step - loss: 0.0775 - accuracy: 0.5086 - val_loss: 0.0712 - val_accuracy: 0.5590 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "1934/1934 [==============================] - 2564s 1s/step - loss: 0.0774 - accuracy: 0.5143 - val_loss: 0.0715 - val_accuracy: 0.5531 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "1934/1934 [==============================] - 2909s 2s/step - loss: 0.0764 - accuracy: 0.5214 - val_loss: 0.0738 - val_accuracy: 0.5411 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "1934/1934 [==============================] - 2898s 1s/step - loss: 0.0773 - accuracy: 0.5160 - val_loss: 0.0705 - val_accuracy: 0.5538 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "1934/1934 [==============================] - 3096s 2s/step - loss: 0.0763 - accuracy: 0.5196 - val_loss: 0.0705 - val_accuracy: 0.5523 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "1934/1934 [==============================] - 2830s 1s/step - loss: 0.0764 - accuracy: 0.5200 - val_loss: 0.0703 - val_accuracy: 0.5605 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "1934/1934 [==============================] - 2463s 1s/step - loss: 0.0761 - accuracy: 0.5217 - val_loss: 0.0709 - val_accuracy: 0.5478 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "1934/1934 [==============================] - 2539s 1s/step - loss: 0.0762 - accuracy: 0.5209 - val_loss: 0.0719 - val_accuracy: 0.5568 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "1934/1934 [==============================] - 2904s 2s/step - loss: 0.0757 - accuracy: 0.5321 - val_loss: 0.0699 - val_accuracy: 0.5471 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "1934/1934 [==============================] - 2866s 1s/step - loss: 0.0759 - accuracy: 0.5210 - val_loss: 0.0706 - val_accuracy: 0.5583 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "1934/1934 [==============================] - 2752s 1s/step - loss: 0.0754 - accuracy: 0.5229 - val_loss: 0.0703 - val_accuracy: 0.5568 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "1934/1934 [==============================] - 2559s 1s/step - loss: 0.0758 - accuracy: 0.5214 - val_loss: 0.0711 - val_accuracy: 0.5516 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "1934/1934 [==============================] - 2551s 1s/step - loss: 0.0750 - accuracy: 0.5265 - val_loss: 0.0697 - val_accuracy: 0.5695 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "1934/1934 [==============================] - 3415s 2s/step - loss: 0.0754 - accuracy: 0.5246 - val_loss: 0.0695 - val_accuracy: 0.5613 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "1934/1934 [==============================] - 3744s 2s/step - loss: 0.0749 - accuracy: 0.5324 - val_loss: 0.0696 - val_accuracy: 0.5561 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "1934/1934 [==============================] - 2864s 1s/step - loss: 0.0751 - accuracy: 0.5252 - val_loss: 0.0711 - val_accuracy: 0.5605 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "1934/1934 [==============================] - 2504s 1s/step - loss: 0.0754 - accuracy: 0.5265 - val_loss: 0.0696 - val_accuracy: 0.5568 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "1934/1934 [==============================] - 2517s 1s/step - loss: 0.0754 - accuracy: 0.5179 - val_loss: 0.0687 - val_accuracy: 0.5680 - lr: 0.0010\n",
      "Model saved to C:\\Users\\Admin\\Documents\\ANN\\Carla Dataset\\saved_model\\saved_model.keras.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf  # Import TensorFlow library\n",
    "import pandas as pd  # Import pandas for handling CSV files\n",
    "import os  # Import os module for file and directory operations\n",
    "import sys  # Import sys module for argument parsing\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping\n",
    "import shutil  # Import shutil for zipping files\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "# Function to load images\n",
    "def load_images(image_paths, target_size=(255, 255)):\n",
    "    images = []  # Initialize an empty list to store images\n",
    "    for img_path in image_paths:\n",
    "        img = load_img(img_path, target_size=target_size)  # Load image and resize\n",
    "        img_array = img_to_array(img)  # Convert image to array\n",
    "        img_array = img_array / 255.0  # Normalize the image to [0, 1]\n",
    "        images.append(img_array)  # Append the image to the list\n",
    "    return tf.convert_to_tensor(images, dtype=tf.float32)  # Convert list of images to a tensor\n",
    "\n",
    "# Function to load data from a given directory and CSV file\n",
    "def load_data(images_dir, csv_file):\n",
    "    data = pd.read_csv(csv_file)  # Read the CSV file into a DataFrame\n",
    "    print(\"CSV Columns:\", data.columns)  # Print the columns in the CSV file to debug the issue\n",
    "\n",
    "    # Print the first few rows to check the data\n",
    "    print(\"First few rows of the data:\\n\", data.head())\n",
    "\n",
    "    # Check for missing values in the DataFrame\n",
    "    if data.isnull().values.any():\n",
    "        print(\"Data contains missing values. Please check the CSV file.\")\n",
    "        print(data.isnull().sum())  # Print count of missing values in each column\n",
    "        return None, None, None, None\n",
    "\n",
    "    # Create full image paths by joining directory and image filename from CSV\n",
    "    image_paths = [os.path.join(images_dir, img_path) for img_path in data['filename'].values]\n",
    "\n",
    "    # Map string labels to numerical labels\n",
    "    class_mapping = {\n",
    "        'car': 0, 'person': 1, 'traffic light': 2, 'red light': 3, 'stop': 4,\n",
    "        'motorbike': 5,'pole': 6, 'edge lane': 7, 'middle lane': 8, 'truck': 9,\n",
    "        'bicycle': 10, 'walk way': 11, 'bus': 12,'Straight and Right Arrow': 13,\n",
    "        'straight and left arrow': 14, 'Green light': 15, 'lanes': 16,\n",
    "        'road': 17,'90': 18, 'bench': 19, 'Yellow light': 20, 'StraightArrow':\n",
    "        21, 'pottedplant': 22, 'left arrow': 23,'Right Arrow': 24, 'bird': 25,\n",
    "        '60': 26,'barrie': 27,'briage': 28, 'motor': 29,\n",
    "      }\n",
    "\n",
    "    # Print unique classes in 'class' column\n",
    "    print(\"Unique classes in the dataset:\", data['class'].unique())\n",
    "\n",
    "    labels = data['class'].map(class_mapping).values  # Convert string labels to numerical labels\n",
    "\n",
    "    # Check for NaN values in labels\n",
    "    if pd.isnull(labels).any():\n",
    "        print(\"Found NaN values in the class column. Please check your class_mapping.\")\n",
    "        print(data[pd.isnull(labels)])  # Print rows with NaN values\n",
    "        return None, None, None, None\n",
    "\n",
    "    # Print unique classes in labels\n",
    "    print(\"Unique classes in labels after mapping:\", pd.unique(labels))\n",
    "\n",
    "    num_classes = len(class_mapping)  # Determine the number of unique classes\n",
    "    labels = tf.keras.utils.to_categorical(labels, num_classes=num_classes)  # Convert labels to one-hot encoding\n",
    "\n",
    "    # Prepare bounding box coordinates and other information\n",
    "    bboxes = data[['xmin', 'ymin', 'xmax', 'ymax']].values  # Extract bounding box coordinates\n",
    "    images = load_images(image_paths)  # Load images using the load_images function\n",
    "    return images, labels, bboxes, num_classes  # Return images, labels, bounding boxes, and number of classes\n",
    "\n",
    "# Load training data\n",
    "train_images_dir = r\"C:\\Users\\Admin\\Documents\\ANN\\Carla Dataset\\train\"  # Directory containing training images\n",
    "train_csv_file = r\"C:\\Users\\Admin\\Documents\\ANN\\Carla Dataset\\train\\_annotations.csv\"  # Update this path to point to your actual CSV file\n",
    "x_train, y_train, _, num_classes = load_data(train_images_dir, train_csv_file)\n",
    "\n",
    "# Check if training data loaded successfully\n",
    "if x_train is None or y_train is None or num_classes is None:\n",
    "    print(\"Failed to load training data. Please check the dataset and the load_data function.\")\n",
    "    sys.exit(1)  # Exit if data loading failed\n",
    "\n",
    "# Load validation data\n",
    "valid_images_dir = r\"C:\\Users\\Admin\\Documents\\ANN\\Carla Dataset\\valid\"  # Directory containing validation images\n",
    "valid_csv_file = r\"C:\\Users\\Admin\\Documents\\ANN\\Carla Dataset\\valid\\_annotations.csv\"  # Update this path as well\n",
    "x_valid, y_valid, _, _ = load_data(valid_images_dir, valid_csv_file)  # Load validation data\n",
    "\n",
    "# Check if validation data loaded successfully\n",
    "if x_valid is None or y_valid is None:\n",
    "    print(\"Failed to load validation data. Please check the dataset and the load_data function.\")\n",
    "    sys.exit(1)  # Exit if data loading failed\n",
    "\n",
    "# Load test data\n",
    "# test_images_dir = \"/content/drive/MyDrive/Dataset/Carla-Dataset/test\"  # Directory containing test images\n",
    "# test_csv_file = \"/content/drive/MyDrive/Dataset/Carla-Dataset/test/_annotations.csv\"  # Update this path as well\n",
    "# x_test, y_test, _, _ = load_data(test_images_dir, test_csv_file)  # Load test data\n",
    "\n",
    "# # Check if test data loaded successfully\n",
    "# if x_test is None or y_test is None:\n",
    "#     print(\"Failed to load test data. Please check the dataset and the load_data function.\")\n",
    "#     sys.exit(1)  # Exit if data loading failed\n",
    "\n",
    "# Data augmentation\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Create a Convolutional neural network\n",
    "# Corrected model creation\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), input_shape=(255, 255, 3)))\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add more layers as needed\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3)))\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(128, (3, 3)))\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512))\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(num_classes))\n",
    "model.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "history = model.compile(optimizer=\"adam\",\n",
    "              # loss=\"sparse_categorical_crossentropy\",,\n",
    "              # loss=\"squared_hinge\",\n",
    "              # loss=\"hinge\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Define callbacks\n",
    "log_dir = r\"C:\\Users\\Admin\\Documents\\ANN\\Carla Dataset\\logs\"  # Directory to save TensorBoard logs\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.1000),\n",
    "    # EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    TensorBoard(log_dir=log_dir)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=3),  # Use a smaller batch size\n",
    "    epochs=30,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "# test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "# print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# Save the trained model\n",
    "# Set the directory to my Google Drive\n",
    "drive_folder_path = r'C:\\Users\\Admin\\Documents\\ANN\\Carla Dataset\\saved_model'\n",
    "os.makedirs(drive_folder_path, exist_ok=True)\n",
    "\n",
    "# Saving the model in the native Keras format\n",
    "keras_filename = os.path.join(drive_folder_path, \"saved_model.keras\")\n",
    "model.save(keras_filename)  # Save the model to .keras file\n",
    "print(f\"Model saved to {keras_filename}.\")\n",
    "\n",
    "# # Zipping the directory containing the saved model\n",
    "# shutil.make_archive(drive_folder_path, 'zip', drive_folder_path)\n",
    "# print(f\"Model directory zipped to {drive_folder_path}.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tjVdkAuFNRr3"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Plot the training history\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[43mplot_training_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m, in \u001b[0;36mplot_training_history\u001b[1;34m(history)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_training_history\u001b[39m(history):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Check if 'val_accuracy' and 'val_loss' exist in history\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     has_val_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m history\u001b[38;5;241m.\u001b[39mhistory\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Plot training & validation accuracy values\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    # Check if 'val_accuracy' and 'val_loss' exist in history\n",
    "    has_val_data = 'val_accuracy' in history.history and 'val_loss' in history.history\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    if has_val_data:\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train'] + (['Validation'] if has_val_data else []), loc='upper left')\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    if has_val_data:\n",
    "        plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train'] + (['Validation'] if has_val_data else []), loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')  # Save the figure as a .png file\n",
    "    plt.show()\n",
    "\n",
    "# Plot the training history\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxdZTgRTNatS"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download('training_history.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1waScw2NzO0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Function to visualize predictions with bounding boxes\n",
    "def predict_and_visualize(model, x_test, y_test, bboxes_test, class_mapping, num_samples=5):\n",
    "    # Predict the class probabilities for the test images\n",
    "    y_pred_prob = model.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Get the reverse mapping from numerical labels to class names\n",
    "    reverse_class_mapping = {v: k for k, v in class_mapping.items()}\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        img = x_test[i].numpy() if isinstance(x_test[i], tf.Tensor) else x_test[i]\n",
    "        true_label = reverse_class_mapping[y_true[i]]\n",
    "        predicted_label = reverse_class_mapping[y_pred[i]]\n",
    "        bbox = bboxes_test[i]\n",
    "\n",
    "        fig, ax = plt.subplots(1)\n",
    "        ax.imshow(img)\n",
    "\n",
    "        # Create a rectangle patch for the bounding box\n",
    "        rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2] - bbox[0], bbox[3] - bbox[1], linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Display true and predicted labels\n",
    "        plt.title(f\"True: {true_label}, Predicted: {predicted_label}\")\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "# Assuming x_test, y_test, and bboxes_test are defined\n",
    "# Example:\n",
    "# x_test = tf.convert_to_tensor([...])  # Replace [...] with actual test images\n",
    "# y_test = tf.convert_to_tensor([...])  # Replace [...] with actual test labels (one-hot encoded)\n",
    "# bboxes_test = np.array([...])  # Replace [...] with actual bounding boxes\n",
    "\n",
    "# Define class mapping\n",
    "class_mapping = {\n",
    "    'car': 0, 'person': 1, 'traffic light': 2, 'red light': 3, 'stop': 4,\n",
    "    'motorbike': 5, 'pole': 6, 'edge lane': 7, 'middle lane': 8, 'truck': 9,\n",
    "    'bicycle': 10, 'walk way': 11, 'bus': 12, 'Straight and Right Arrow': 13,\n",
    "    'straight and left arrow': 14, 'Green light': 15, 'lanes': 16,\n",
    "    'road': 17, '90': 18, 'bench': 19, 'Yellow light': 20, 'StraightArrow':\n",
    "    21, 'pottedplant': 22, 'left arrow': 23, 'Right Arrow': 24, 'bird': 25,\n",
    "    '60': 26, 'barrie': 27, 'bridge': 28, 'motor': 29\n",
    "}\n",
    "\n",
    "# Call the function with example data\n",
    "predict_and_visualize(model, x_test, y_test, bboxes_test, class_mapping, num_samples=5)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
